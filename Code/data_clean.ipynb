{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "479d2e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import important libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b5f060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Validation\n",
    "def validate_data(\n",
    "        df: pd.DataFrame,\n",
    "        total_col: str = \"TotalResponses\",\n",
    "        correct_col: str = \"CorrectResponses\",\n",
    "        level_col: str = \"Level\",\n",
    "        max_lives : int = 3,\n",
    "\n",
    ") -> Tuple[pd.DataFrame, List[str]]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Validates and normalises the aggregate Number Recall data so we can reconstruct trial-level rows.\n",
    "    Rules assumed from your spec:\n",
    "      - Level == CorrectResponses (should hold; if not, we trust CorrectResponses).\n",
    "      - TotalResponses = CorrectResponses + wrong_attempts, with wrong_attempts <= max_lives.\n",
    "      - Drop rows with no attempts (TotalResponses <= 0).\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    notes: List[str] = []\n",
    "\n",
    "    # Required columns present?\n",
    "    for c in [total_col, correct_col, level_col]:\n",
    "        if c not in df.columns:\n",
    "            raise KeyError(f\"Missing required column: {c}\")\n",
    "        \n",
    "    # If Level missing, backfill from CorrectResponses\n",
    "    df[level_col] = df[level_col].fillna(df[correct_col])\n",
    "\n",
    "    # Drop rows with nulls in the key columns\n",
    "    before = len(df)\n",
    "    df = df.dropna(subset=[total_col, correct_col, level_col]).copy()\n",
    "    dropped_nulls = before - len(df)\n",
    "    if dropped_nulls > 0:\n",
    "        notes.append(f\"[Drop] Removed {dropped_nulls} rows with nulls in {total_col}/{correct_col}/{level_col}.\")\n",
    "\n",
    "    # Enforce Level == CorrectResponses\n",
    "    mask_lvl_mismatch = df[level_col] != df[correct_col]\n",
    "    if mask_lvl_mismatch.any():\n",
    "        n = int(mask_lvl_mismatch.sum())\n",
    "        notes.append(f\"[Fix] Level != CorrectResponses for {n} rows. Overwrote Level with CorrectResponses.\")\n",
    "        df.loc[mask_lvl_mismatch, level_col] = df.loc[mask_lvl_mismatch, correct_col]\n",
    "\n",
    "    # Enforce TotalResponses >= CorrectResponses\n",
    "    mask_too_low = df[total_col] < df[correct_col]\n",
    "    if mask_too_low.any():\n",
    "        n = int(mask_too_low.sum())\n",
    "        notes.append(f\"[Fix] TotalResponses < CorrectResponses in {n} rows. Set TotalResponses = CorrectResponses.\")\n",
    "        df.loc[mask_too_low, total_col] = df.loc[mask_too_low, correct_col]\n",
    "\n",
    "    # Enforce wrong attempts <= max_lives\n",
    "    wrong_attempts = df[total_col] - df[correct_col]\n",
    "    mask_too_high = wrong_attempts > max_lives\n",
    "    if mask_too_high.any():\n",
    "        n = int(mask_too_high.sum())\n",
    "        notes.append(f\"[Fix] Wrong attempts exceeded {max_lives} in {n} rows. \"\n",
    "                     f\"Capped at CorrectResponses + {max_lives}.\")\n",
    "        df.loc[mask_too_high, total_col] = df.loc[mask_too_high, correct_col] + max_lives\n",
    "\n",
    "    # Drop rows with no attempts\n",
    "    before2 = len(df)\n",
    "    df = df[df[total_col] > 0].copy()\n",
    "    dropped_zero = before2 - len(df)\n",
    "    if dropped_zero > 0:\n",
    "        notes.append(f\"[Drop] Removed {dropped_zero} rows with {total_col} <= 0.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6d63755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Reconstruct data for IRT Model ie item-response rows\n",
    "def row_to_item_responses(correct, total):\n",
    "    \"\"\"\n",
    "    Build item_id and response lists for a single aggregate row.\n",
    "    - item_id = 1..total\n",
    "    - first 'correct' are 1, remainder are 0\n",
    "\n",
    "    \"\"\"\n",
    "    total = int(total)\n",
    "    correct = int(correct)\n",
    "    items = list(range(1, total + 1))\n",
    "    responses = [1] * correct + [0] * max(0, total - correct)\n",
    "\n",
    "    return items, responses\n",
    "\n",
    "def explode_trials(\n",
    "    df: pd.DataFrame,\n",
    "    id_col: str = \"AccountId\",\n",
    "    total_col: str = \"TotalResponses\",\n",
    "    correct_col: str = \"CorrectResponses\",\n",
    "    keep_session: bool = False\n",
    "\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Produce a long table with participant_id, item_id, response.\n",
    "\n",
    "    \"\"\"\n",
    "    items_and_responses = df[[correct_col, total_col]].apply(\n",
    "        lambda r: row_to_item_responses(r[correct_col], r[total_col]), axis=1\n",
    "    )\n",
    "    df = df.copy()\n",
    "    df[\"__items\"] = [ir[0] for ir in items_and_responses]\n",
    "    df[\"__responses\"] = [ir[1] for ir in items_and_responses]\n",
    "\n",
    "    long_df = df[[id_col, \"__items\", \"__responses\"]].explode([\"__items\", \"__responses\"], ignore_index=True)\n",
    "    out = long_df.rename(columns={id_col: \"participant_id\", \"__items\": \"item_id\", \"__responses\": \"response\"})\n",
    "    return out[[\"participant_id\", \"item_id\", \"response\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c106c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. End to end function\n",
    "def transform_number_recall_to_irt(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    id_col: str = \"AccountId\",\n",
    "    total_col: str = \"TotalResponses\",\n",
    "    correct_col: str = \"CorrectResponses\",\n",
    "    level_col: str = \"Level\",\n",
    "    max_lives: int = 3,\n",
    ") -> pd.DataFrame:\n",
    "    clean = validate_data(\n",
    "        df,\n",
    "        total_col=total_col,\n",
    "        correct_col=correct_col,\n",
    "        level_col=level_col,\n",
    "        max_lives=max_lives,\n",
    "    )\n",
    "    out = explode_trials(\n",
    "        clean,\n",
    "        id_col=id_col,\n",
    "        total_col=total_col,\n",
    "        correct_col=correct_col,\n",
    "    )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfa592ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def append_original_columns_to_irt(\n",
    "    irt_data: pd.DataFrame,\n",
    "    original_df: pd.DataFrame,\n",
    "    *,\n",
    "    id_col: str = \"AccountId\",                 # id column in original_df\n",
    "    irt_id_col: str = \"participant_id\",        # id column in irt_data\n",
    "    cols_to_append: Optional[List[str]] = None # which original columns to append\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Append selected columns from the original aggregate data to the long-form IRT rows.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    irt_data : DataFrame\n",
    "        Output from your transform_number_recall_to_irt(...) function (cols: participant_id, item_id, response).\n",
    "    original_df : DataFrame\n",
    "        The original aggregate table that contains id_col plus columns you want to append.\n",
    "    id_col : str\n",
    "        Identifier in original_df (e.g., 'AccountId').\n",
    "    irt_id_col : str\n",
    "        Identifier in irt_data (e.g., 'participant_id').\n",
    "    cols_to_append : list[str] | None\n",
    "        Columns from original_df to append. Defaults to ['Score', 'Percentage', 'Percentile'].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        irt_data with the requested columns appended per participant.\n",
    "    \"\"\"\n",
    "    if cols_to_append is None:\n",
    "        cols_to_append = [\"Score\", \"Percentage\", \"Percentile\"]\n",
    "\n",
    "    # Validate presence\n",
    "    missing = [c for c in [id_col, *cols_to_append] if c not in original_df.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing required column(s) in original_df: {missing}\")\n",
    "\n",
    "    if irt_id_col not in irt_data.columns:\n",
    "        raise KeyError(f\"Missing '{irt_id_col}' column in irt_data.\")\n",
    "\n",
    "    # Make a slim, deduplicated right table\n",
    "    right = (\n",
    "        original_df[[id_col, *cols_to_append]]\n",
    "        .dropna(subset=[id_col])\n",
    "        .drop_duplicates(subset=[id_col])\n",
    "        .copy()\n",
    "    )\n",
    "\n",
    "    # Merge onto IRT rows\n",
    "    merged = irt_data.merge(\n",
    "        right,\n",
    "        how=\"left\",\n",
    "        left_on=irt_id_col,\n",
    "        right_on=id_col,\n",
    "        validate=\"many_to_one\" if right[id_col].is_unique else \"many_to_many\"\n",
    "    ).drop(columns=[id_col], errors=\"ignore\")\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "332667e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"/Users/op24226/Desktop/PsychGames/Data/NumberRecall_UserScores.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6db06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "irt_df = transform_number_recall_to_irt(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bfd29c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "irt_scores = append_original_columns_to_irt(irt_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1988054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change irt data to mirt format\n",
    "\n",
    "#Get the maximum item_id for each participant\n",
    "max_items = irt_df.groupby('participant_id')['item_id'].max().max()\n",
    "\n",
    "# Create a pivot table with aggfunc to handle multiple values\n",
    "wide_df = irt_df.pivot_table(\n",
    "    index='participant_id',\n",
    "    columns='item_id',\n",
    "    values='response',\n",
    "    aggfunc='first'  # Takes the first response if there are multiple\n",
    ")\n",
    "\n",
    "# Ensure all item_ids up to max are present\n",
    "for i in range(1, max_items + 1):\n",
    "    if i not in wide_df.columns:\n",
    "        wide_df[i] = np.nan\n",
    "\n",
    "# Sort columns numerically\n",
    "wide_df = wide_df.reindex(sorted(wide_df.columns), axis=1)\n",
    "\n",
    "wide_df.columns = [f'item_id {col}' for col in wide_df.columns]\n",
    "\n",
    "wide_df = wide_df.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71b18f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
